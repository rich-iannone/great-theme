import os
import re
import shutil
from importlib import resources
from pathlib import Path

import yaml


class GreatDocs:
    """
    GreatDocs class for creating beautiful API documentation sites.

    This class provides methods to install assets and configure
    Quarto projects with the great-docs styling and functionality.
    """

    def __init__(self, project_path: str | None = None, docs_dir: str | None = None):
        """
        Initialize GreatDocs instance.

        Parameters
        ----------
        project_path
            Path to the Quarto project root directory. Defaults to current directory.
        docs_dir
            Path to the documentation directory relative to project_path.
            If not provided, will be auto-detected or user will be prompted.
        """
        self.project_root = Path(project_path or os.getcwd())
        self.docs_dir = self._find_or_create_docs_dir(docs_dir)
        self.project_path = self.project_root / self.docs_dir
        try:
            # Python 3.9+
            self.package_path = Path(resources.files("great_docs"))
        except AttributeError:
            # Fallback for older Python versions
            import importlib_resources  # type: ignore[import-not-found]

            self.package_path = Path(importlib_resources.files("great_docs"))
        self.assets_path = self.package_path / "assets"

    def _find_or_create_docs_dir(self, docs_dir: str | None = None) -> Path:
        """
        Find or create the documentation directory.

        Parameters
        ----------
        docs_dir
            User-specified docs directory path.

        Returns
        -------
        Path
            Path to the docs directory relative to project root.
        """
        if docs_dir:
            return Path(docs_dir)

        # Common documentation directory names
        common_docs_dirs = ["docs", "documentation", "site", "docsrc", "doc"]

        # First, look for existing _quarto.yml in common locations
        for dir_name in common_docs_dirs:
            potential_dir = self.project_root / dir_name
            if (potential_dir / "_quarto.yml").exists():
                print(f"Found existing Quarto project in '{dir_name}/' directory")
                return Path(dir_name)

        # Check if _quarto.yml exists in project root
        if (self.project_root / "_quarto.yml").exists():
            print("Found _quarto.yml in project root")
            return Path(".")

        # Look for any existing common docs directories (even without _quarto.yml)
        for dir_name in common_docs_dirs:
            potential_dir = self.project_root / dir_name
            if potential_dir.exists() and potential_dir.is_dir():
                response = input(
                    f"Found existing '{dir_name}/' directory. Install great-docs here? [Y/n]: "
                )
                if response.lower() != "n":
                    return Path(dir_name)

        # No existing docs directory found - ask user
        print("\nNo documentation directory detected.")
        print("Where would you like to install great-docs?")
        print("  1. docs/ (recommended for most projects)")
        print("  2. Current directory (project root)")
        print("  3. Custom directory")

        choice = input("Enter choice [1]: ").strip() or "1"

        if choice == "1":
            return Path("docs")
        elif choice == "2":
            return Path(".")
        elif choice == "3":
            custom_dir = input("Enter directory path: ").strip()
            return Path(custom_dir) if custom_dir else Path("docs")
        else:
            print("Invalid choice, using 'docs/' as default")
            return Path("docs")

    def install(self, force: bool = False, skip_quartodoc: bool = False) -> None:
        """
        Install great-docs assets and configuration to the project.

        This method copies the necessary CSS files and post-render script to your Quarto project
        directory, and automatically updates your `_quarto.yml` configuration file to use the
        great-docs styling.

        Parameters
        ----------
        force
            If True, overwrite existing files without prompting. Default is False.
        skip_quartodoc
            If True, skip adding quartodoc configuration. Useful for testing or when
            quartodoc is not needed. Default is False.

        Examples
        --------
        Install documentation in the current directory:

        ```python
        from great_docs import GreatDocs

        docs = GreatDocs()
        docs.install()
        ```

        Install documentation in a specific project directory, overwriting existing files:

        ```python
        docs = GreatDocs("/path/to/my/project")
        docs.install(force=True)
        ```
        """
        print("Installing great-docs to your quartodoc project...")

        # Create docs directory if it doesn't exist
        self.project_path.mkdir(parents=True, exist_ok=True)
        print(f"Using directory: {self.project_path.relative_to(self.project_root)}")

        # Create necessary directories
        scripts_dir = self.project_path / "scripts"
        scripts_dir.mkdir(exist_ok=True)

        # Copy post-render script
        post_render_src = self.assets_path / "post-render.py"
        post_render_dst = scripts_dir / "post-render.py"

        if post_render_dst.exists() and not force:
            response = input(f"{post_render_dst} already exists. Overwrite? [y/N]: ")
            if response.lower() != "y":
                print("Skipping post-render.py")
            else:
                shutil.copy2(post_render_src, post_render_dst)
                print(f"Copied {post_render_dst}")
        else:
            shutil.copy2(post_render_src, post_render_dst)
            print(f"Copied {post_render_dst}")

        # Copy CSS file
        css_src = self.assets_path / "styles.css"
        css_dst = self.project_path / "great-docs.css"

        if css_dst.exists() and not force:
            response = input(f"{css_dst} already exists. Overwrite? [y/N]: ")
            if response.lower() != "y":
                print("Skipping great-docs.css")
            else:
                shutil.copy2(css_src, css_dst)
                print(f"Copied {css_dst}")
        else:
            shutil.copy2(css_src, css_dst)
            print(f"Copied {css_dst}")

        # Copy .gitignore file
        gitignore_src = self.assets_path / ".gitignore"
        gitignore_dst = self.project_path / ".gitignore"

        if gitignore_dst.exists() and not force:
            # Append to existing .gitignore if it doesn't already contain our entries
            with open(gitignore_dst, "r") as f:
                existing_content = f.read()

            if "_site/" not in existing_content:
                with open(gitignore_src, "r") as f:
                    new_content = f.read()
                with open(gitignore_dst, "a") as f:
                    f.write("\n" + new_content)
                print(f"Appended to {gitignore_dst}")
            else:
                print("Skipping .gitignore (already contains _site/ entry)")
        else:
            shutil.copy2(gitignore_src, gitignore_dst)
            print(f"Copied {gitignore_dst}")

        # Update _quarto.yml configuration
        self._update_quarto_config()

        # Create index.qmd from README.md if it doesn't exist
        self._create_index_from_readme()

        # Add quartodoc configuration if not present
        if not skip_quartodoc:
            self._add_quartodoc_config()
            self._update_sidebar_from_sections()
            self._update_reference_index_frontmatter()

        print("\nGreat Docs installation complete!")
        if not skip_quartodoc:
            print("\nNext steps:")
            print("1. Review the generated quartodoc configuration in _quarto.yml")
            print("2. Run `great-docs build` to generate docs and build your site")
            print("   (This runs `quartodoc build` followed by `quarto render`)")
            print(f"3. Open {self.project_path / '_site' / 'index.html'} to preview your site")
            print("\nOther helpful commands:")
            print("  great-docs build          # Build everything")
            print("  great-docs build --watch  # Watch for changes and rebuild")
            print("  great-docs preview        # Build and serve locally")
        else:
            print("\nNext steps:")
            print("1. Run `quarto render` to build your site")

    def _detect_package_name(self) -> str | None:
        """
        Detect the Python package name from project structure.

        Returns
        -------
        str | None
            The detected package name, or None if not found.
        """
        # Look for pyproject.toml
        pyproject_path = self.project_root / "pyproject.toml"
        if pyproject_path.exists():
            import tomllib

            with open(pyproject_path, "rb") as f:
                try:
                    data = tomllib.load(f)
                    return data.get("project", {}).get("name")
                except Exception:
                    return None

        # Look for setup.py
        setup_py = self.project_root / "setup.py"
        if setup_py.exists():
            with open(setup_py, "r") as f:
                content = f.read()
                # Simple regex to find name="..." in setup()
                import re

                match = re.search(r'name\s*=\s*["\']([^"\']+)["\']', content)
                if match:
                    return match.group(1)

        # Look for a single Python package directory
        potential_packages = [
            d
            for d in self.project_root.iterdir()
            if d.is_dir() and (d / "__init__.py").exists() and not d.name.startswith(".")
        ]
        if len(potential_packages) == 1:
            return potential_packages[0].name

        return None

    def _normalize_package_name(self, package_name: str) -> str:
        """
        Convert a package name to its importable form.

        PyPI package names can use hyphens (e.g., 'great-docs') but Python
        imports must use underscores (e.g., 'great_docs'). This method handles
        the conversion.

        Parameters
        ----------
        package_name
            The package name (potentially with hyphens)

        Returns
        -------
        str
            The importable package name (with underscores)
        """
        return package_name.replace("-", "_")

    def _find_package_root(self) -> Path:
        """
        Find the actual package root directory (where pyproject.toml or setup.py exists).

        When the docs directory is the current directory, project_root might point to
        the docs dir rather than the package root. This method searches upward to find
        the actual package root.

        Returns
        -------
        Path
            The package root directory
        """
        current = self.project_root

        # Search upward from current directory
        for _ in range(5):  # Limit search to 5 levels up
            if (current / "pyproject.toml").exists() or (current / "setup.py").exists():
                return current
            parent = current.parent
            if parent == current:  # Reached filesystem root
                break
            current = parent

        # Fallback to project_root if we can't find it
        return self.project_root

    def _get_package_metadata(self) -> dict:
        """
        Extract package metadata from pyproject.toml for sidebar.

        Returns
        -------
        dict
            Dictionary containing package metadata like license, authors, URLs, etc.
        """
        metadata = {}
        package_root = self._find_package_root()
        pyproject_path = package_root / "pyproject.toml"

        if not pyproject_path.exists():
            return metadata

        import tomllib

        try:
            with open(pyproject_path, "rb") as f:
                data = tomllib.load(f)
                project = data.get("project", {})

                # Extract relevant fields
                metadata["license"] = project.get("license", {}).get("text") or project.get(
                    "license", {}
                ).get("file", "")
                metadata["authors"] = project.get("authors", [])
                metadata["maintainers"] = project.get("maintainers", [])
                metadata["urls"] = project.get("urls", {})
                metadata["requires_python"] = project.get("requires-python", "")
                metadata["keywords"] = project.get("keywords", [])
                metadata["description"] = project.get("description", "")
                metadata["optional_dependencies"] = project.get("optional-dependencies", {})

                # Extract rich author metadata and exclude list from tool.great-docs if available
                tool_config = data.get("tool", {}).get("great-docs", {})
                metadata["rich_authors"] = tool_config.get("authors", [])
                metadata["exclude"] = tool_config.get("exclude", [])
                metadata["include"] = tool_config.get("include", [])
                # Discovery method: "dir" (default) or "all" (use __all__)
                metadata["discovery_method"] = tool_config.get("discovery_method", "dir")

                # Source link configuration
                source_config = tool_config.get("source", {})
                metadata["source_link_enabled"] = source_config.get("enabled", True)
                metadata["source_link_branch"] = source_config.get("branch", None)
                metadata["source_link_path"] = source_config.get("path", None)
                metadata["source_link_placement"] = source_config.get("placement", "usage")

                # Family/group configuration for API organization
                metadata["families"] = tool_config.get("families", {})

        except Exception:
            pass

        return metadata

    def _get_github_repo_info(self) -> tuple[str | None, str | None, str | None]:
        """
        Extract GitHub repository information from pyproject.toml.

        Returns
        -------
        tuple[str | None, str | None, str | None]
            A tuple of (owner, repo_name, base_url) or (None, None, None) if not found.
        """
        metadata = self._get_package_metadata()
        urls = metadata.get("urls", {})

        # Look for repository URL in various common key names
        repo_url = None
        for key in ["Repository", "repository", "Source", "source", "GitHub", "github"]:
            if key in urls:
                repo_url = urls[key]
                break

        if not repo_url or "github.com" not in repo_url:
            return None, None, None

        # Parse the GitHub URL to extract owner and repo
        # Handles formats like:
        # - https://github.com/owner/repo
        # - https://github.com/owner/repo.git
        # - git@github.com:owner/repo.git
        github_pattern = r"github\.com[/:]([^/]+)/([^/\s.]+)"
        match = re.search(github_pattern, repo_url)

        if match:
            owner = match.group(1)
            repo = match.group(2).rstrip(".git")
            base_url = f"https://github.com/{owner}/{repo}"
            return owner, repo, base_url

        return None, None, None

    def _get_source_location(self, package_name: str, item_name: str) -> dict | None:
        """
        Get source file and line numbers for a class, method, or function.

        Uses griffe for static analysis to avoid import side effects.

        Parameters
        ----------
        package_name
            The name of the package containing the item.
        item_name
            The fully qualified name of the item (e.g., "ClassName" or "ClassName.method_name").

        Returns
        -------
        dict | None
            Dictionary with file path and line numbers, or None if not found.
        """
        try:
            import griffe

            normalized_name = package_name.replace("-", "_")

            # Load the package with griffe
            try:
                pkg = griffe.load(normalized_name)
            except Exception:
                return None

            # Navigate to the item (handle dotted names like "ClassName.method")
            parts = item_name.split(".")
            obj = pkg

            for part in parts:
                if part not in obj.members:
                    return None
                obj = obj.members[part]

            # Get source information
            if not hasattr(obj, "lineno") or obj.lineno is None:
                return None

            # Get the file path relative to package root
            if hasattr(obj, "filepath") and obj.filepath:
                filepath = str(obj.filepath)
            else:
                return None

            # Get end line number
            end_lineno = getattr(obj, "endlineno", obj.lineno)

            return {
                "file": filepath,
                "start_line": obj.lineno,
                "end_line": end_lineno or obj.lineno,
            }

        except ImportError:
            return None
        except Exception:
            return None

    def _build_github_source_url(
        self, source_location: dict, branch: str | None = None
    ) -> str | None:
        """
        Build a GitHub URL for viewing source code at specific line numbers.

        Parameters
        ----------
        source_location
            Dictionary with file path and line numbers.
        branch
            Git branch/tag to link to. If None, attempts to detect from git
            or falls back to 'main'.

        Returns
        -------
        str | None
            Full GitHub URL with line anchors, or None if repo info not available.
        """
        owner, repo, base_url = self._get_github_repo_info()

        if not base_url:
            return None

        # Determine the branch/ref to use
        if branch is None:
            branch = self._detect_git_ref()

        # Get the file path relative to the repository root
        filepath = source_location.get("file", "")
        package_root = self._find_package_root()

        # Handle source path configuration for monorepos
        metadata = self._get_package_metadata()
        source_path = metadata.get("source_link_path")

        if source_path:
            # Custom source path specified (for monorepos)
            relative_path = f"{source_path}/{Path(filepath).name}"
        else:
            # Try to make the path relative to package root
            try:
                filepath_obj = Path(filepath)
                if filepath_obj.is_absolute():
                    relative_path = str(filepath_obj.relative_to(package_root))
                else:
                    relative_path = filepath
            except ValueError:
                # Path is not relative to package root, use as-is
                relative_path = filepath

        # Build the URL with line number anchors
        start_line = source_location.get("start_line", 1)
        end_line = source_location.get("end_line", start_line)

        url = f"{base_url}/blob/{branch}/{relative_path}"

        if start_line == end_line:
            url += f"#L{start_line}"
        else:
            url += f"#L{start_line}-L{end_line}"

        return url

    def _detect_git_ref(self) -> str:
        """
        Detect the current git branch or tag.

        Returns
        -------
        str
            The current branch/tag name, or 'main' as fallback.
        """
        import subprocess

        package_root = self._find_package_root()

        # First check if there's a configured branch in metadata
        metadata = self._get_package_metadata()
        configured_branch = metadata.get("source_link_branch")
        if configured_branch:
            return configured_branch

        try:
            # Try to get the current tag first (for versioned docs)
            result = subprocess.run(
                ["git", "describe", "--tags", "--exact-match"],
                cwd=package_root,
                capture_output=True,
                text=True,
            )
            if result.returncode == 0:
                return result.stdout.strip()

            # Fall back to branch name
            result = subprocess.run(
                ["git", "rev-parse", "--abbrev-ref", "HEAD"],
                cwd=package_root,
                capture_output=True,
                text=True,
            )
            if result.returncode == 0:
                branch = result.stdout.strip()
                if branch != "HEAD":
                    return branch

        except Exception:
            pass

        # Default fallback
        return "main"

    def _generate_source_links_json(self, package_name: str) -> None:
        """
        Generate a JSON file mapping object names to their GitHub source URLs.

        This file is used by the post-render script to inject source links
        into the HTML documentation.

        Parameters
        ----------
        package_name
            The name of the package to generate source links for.
        """
        import json

        metadata = self._get_package_metadata()

        # Check if source links are enabled
        if not metadata.get("source_link_enabled", True):
            print("Source links disabled in configuration")
            return

        # Check if we have GitHub repo info
        owner, repo, base_url = self._get_github_repo_info()
        if not base_url:
            print("No GitHub repository URL found, skipping source links")
            return

        print(f"Generating source links for {package_name}...")

        source_links: dict[str, dict] = {}
        normalized_name = package_name.replace("-", "_")

        # Get all exports
        exports = self._get_package_exports(package_name)
        if not exports:
            return

        # Get branch for source links
        branch = self._detect_git_ref()
        print(f"Using git ref: {branch}")

        # Generate source links for each export
        for item_name in exports:
            source_loc = self._get_source_location(normalized_name, item_name)
            if source_loc:
                github_url = self._build_github_source_url(source_loc, branch)
                if github_url:
                    source_links[item_name] = {
                        "url": github_url,
                        "file": source_loc.get("file", ""),
                        "start_line": source_loc.get("start_line", 0),
                        "end_line": source_loc.get("end_line", 0),
                    }

            # Also get source links for methods of classes
            categories = self._categorize_api_objects(package_name, [item_name])
            if item_name in categories.get("classes", []):
                method_names = categories.get("class_method_names", {}).get(item_name, [])
                for method_name in method_names:
                    full_name = f"{item_name}.{method_name}"
                    method_loc = self._get_source_location(normalized_name, full_name)
                    if method_loc:
                        method_url = self._build_github_source_url(method_loc, branch)
                        if method_url:
                            source_links[full_name] = {
                                "url": method_url,
                                "file": method_loc.get("file", ""),
                                "start_line": method_loc.get("start_line", 0),
                                "end_line": method_loc.get("end_line", 0),
                            }

        # Write to JSON file in the docs directory
        source_links_path = self.project_path / "_source_links.json"
        with open(source_links_path, "w", encoding="utf-8") as f:
            json.dump(source_links, f, indent=2)

        print(f"Generated source links for {len(source_links)} items")

    def _find_package_init(self, package_name: str) -> Path | None:
        """
        Find the __init__.py file for a package, searching common locations.

        This handles packages with non-standard structures like Rust bindings
        that may have their Python code in subdirectories like python/, src/, etc.

        Parameters
        ----------
        package_name
            The name of the package to find.

        Returns
        -------
        Path | None
            Path to the __init__.py file, or None if not found.
        """
        # Normalize package name (replace dashes with underscores)
        normalized_name = package_name.replace("-", "_")

        # Common locations to search for package directories
        search_paths = [
            self.project_root / package_name,
            self.project_root / normalized_name,
            self.project_root / "python" / package_name,
            self.project_root / "python" / normalized_name,
            self.project_root / "src" / package_name,
            self.project_root / "src" / normalized_name,
            self.project_root / "lib" / package_name,
            self.project_root / "lib" / normalized_name,
        ]

        for package_dir in search_paths:
            if not package_dir.exists() or not package_dir.is_dir():
                continue

            init_file = package_dir / "__init__.py"
            if init_file.exists():
                # Verify this is likely the right __init__.py by checking for __version__
                try:
                    with open(init_file, "r", encoding="utf-8") as f:
                        content = f.read()
                        # Check if it has __version__ (good indicator of main package __init__)
                        if "__version__" in content or "__all__" in content:
                            return init_file
                except Exception:
                    continue

        return None

    def _parse_package_exports(self, package_name: str) -> list | None:
        """
        Parse __all__ from package's __init__.py to get public API.

        Also checks for __gt_exclude__ in __init__.py or exclude in [tool.great-docs]
        to filter out non-documentable items.

        Parameters
        ----------
        package_name
            The name of the package to parse.

        Returns
        -------
        list | None
            List of public names from __all__ (filtered by exclusions), or None if not found.
        """
        # Find the package's __init__.py file
        init_file = self._find_package_init(package_name)
        if not init_file:
            print(f"Could not locate __init__.py for package '{package_name}'")
            return None

        print(f"Found package __init__.py at: {init_file.relative_to(self.project_root)}")

        # Get exclusions from pyproject.toml [tool.great-docs]
        metadata = self._get_package_metadata()
        config_exclude = metadata.get("exclude", [])

        try:
            with open(init_file, "r", encoding="utf-8") as f:
                content = f.read()

            # Try to extract __all__ and __gt_exclude__ using AST (safer than eval)
            import ast

            tree = ast.parse(content)

            all_exports = None
            gt_exclude = []

            for node in ast.walk(tree):
                if isinstance(node, ast.Assign):
                    for target in node.targets:
                        # Extract __all__
                        if isinstance(target, ast.Name) and target.id == "__all__":
                            if isinstance(node.value, ast.List):
                                all_exports = []
                                for elt in node.value.elts:
                                    if isinstance(elt, ast.Constant) and isinstance(elt.value, str):
                                        all_exports.append(elt.value)

                        # Extract __gt_exclude__ (legacy support)
                        if isinstance(target, ast.Name) and target.id == "__gt_exclude__":
                            if isinstance(node.value, ast.List):
                                for elt in node.value.elts:
                                    if isinstance(elt, ast.Constant) and isinstance(elt.value, str):
                                        gt_exclude.append(elt.value)

            if all_exports:
                print(f"Successfully parsed __all__ with {len(all_exports)} exports")

                # Combine exclusions from both sources
                all_exclude = list(set(gt_exclude + config_exclude))

                # Filter out excluded items
                if all_exclude:
                    filtered = [e for e in all_exports if e not in all_exclude]
                    excluded_count = len(all_exports) - len(filtered)
                    if excluded_count > 0:
                        source = []
                        if gt_exclude:
                            source.append("__gt_exclude__")
                        if config_exclude:
                            source.append("[tool.great-docs] exclude")
                        print(
                            f"Filtered out {excluded_count} item(s) from {' and '.join(source)}: {', '.join(all_exclude)}"
                        )
                    return filtered
                else:
                    return all_exports

            print("No __all__ definition found in __init__.py")
            return None
        except Exception as e:
            print(f"Error parsing __all__: {type(e).__name__}: {e}")
            return None

    # Auto-excluded names that are typically not meant for documentation
    # These are common internal/utility exports that most packages don't want documented
    AUTO_EXCLUDE = {
        # CLI and entry points
        "main",  # CLI entry point function
        "cli",  # CLI module
        # Version and metadata
        "version",  # Version string/function
        "VERSION",  # Uppercase version constant
        "VERSION_INFO",  # Version info tuple
        # Common module re-exports
        "core",  # Core module
        "utils",  # Utilities module
        "helpers",  # Helpers module
        "constants",  # Constants module
        "config",  # Config module
        "settings",  # Settings module
        # Standard library re-exports
        "PackageNotFoundError",  # importlib.metadata exception
        "typing",  # typing module re-export
        "annotations",  # annotations module re-export
        "TYPE_CHECKING",  # typing.TYPE_CHECKING constant
        # Logging
        "logger",  # Module-level logger instance
        "log",  # Alternative logger name
        "logging",  # logging module re-export
    }

    def _discover_package_exports(self, package_name: str) -> list | None:
        """
        Discover public API objects using griffe introspection.

        This method uses griffe (quartodoc's introspection library) to statically analyze the
        package and discover all public objects by filtering out private/internal names (those
        starting with underscore).

        Auto-excludes common internal names (see `AUTO_EXCLUDE`) unless they are explicitly included
        via the `include` option in `pyproject.toml`.

        Parameters
        ----------
        package_name
            The name of the package to discover exports from.

        Returns
        -------
        list | None
            List of public names discovered (filtered by exclusions), or `None` if discovery failed.
        """
        try:
            import griffe

            # Normalize package name (replace dashes with underscores)
            normalized_name = package_name.replace("-", "_")

            # Load the package using griffe
            try:
                pkg = griffe.load(normalized_name)
            except Exception as e:
                print(f"Warning: Could not load package with griffe ({type(e).__name__})")
                return None

            # Get all members from the package (equivalent to dir(package))
            all_members = list(pkg.members.keys())

            # Filter out private names (starting with underscore)
            # This also filters out dunder names like __version__, __all__, etc.
            public_members = [name for name in all_members if not name.startswith("_")]

            print(f"Discovered {len(public_members)} public names")

            # Get config from pyproject.toml [tool.great-docs]
            metadata = self._get_package_metadata()
            config_exclude = set(metadata.get("exclude", []))
            config_include = set(metadata.get("include", []))

            # Apply auto-exclusions (but respect explicit includes)
            auto_excluded = self.AUTO_EXCLUDE - config_include
            if auto_excluded:
                auto_excluded_found = [name for name in public_members if name in auto_excluded]
                if auto_excluded_found:
                    print(
                        f"Auto-excluding {len(auto_excluded_found)} item(s): "
                        f"{', '.join(sorted(auto_excluded_found))}"
                    )

            # Combine all exclusions (auto + user-specified), minus explicit includes
            all_exclude = (auto_excluded | config_exclude) - config_include

            # Filter out excluded items
            filtered = [name for name in public_members if name not in all_exclude]

            # Report user-specified exclusions separately
            if config_exclude:
                user_excluded_found = [
                    name
                    for name in public_members
                    if name in config_exclude and name not in auto_excluded
                ]
                if user_excluded_found:
                    print(
                        f"Filtered out {len(user_excluded_found)} item(s) from [tool.great-docs] exclude: "
                        f"{', '.join(sorted(user_excluded_found))}"
                    )

            # Report explicit includes that overrode auto-exclusions
            if config_include:
                overridden = [
                    name
                    for name in public_members
                    if name in config_include and name in self.AUTO_EXCLUDE
                ]
                if overridden:
                    print(
                        f"Including {len(overridden)} auto-excluded item(s) via [tool.great-docs] include: "
                        f"{', '.join(sorted(overridden))}"
                    )

            # Super-safe filtering: try each object with quartodoc's get_object
            # If it fails for ANY reason, exclude it - this catches:
            # - Cyclic aliases
            # - Unresolvable aliases
            # - Rust/PyO3 objects (KeyError)
            # - Submodules (which would cause recursive documentation issues)
            # - Any other edge case that would crash quartodoc build
            safe_exports = []
            failed_exports = {}  # name -> error type for reporting

            # Try to use quartodoc's get_object for validation
            quartodoc_get_object = None
            try:
                from functools import partial

                from quartodoc import get_object as qd_get_object

                # quartodoc uses parser="numpy" by default which affects alias resolution
                quartodoc_get_object = partial(qd_get_object, dynamic=True, parser="numpy")
            except ImportError:
                pass

            # Try to import the actual package to detect modules
            actual_package = None
            try:
                import importlib

                actual_package = importlib.import_module(normalized_name)
            except ImportError:
                pass

            for name in filtered:
                # First check if this is a submodule - these should be excluded
                # because documenting them recursively documents all their members
                if actual_package is not None:
                    runtime_obj = getattr(actual_package, name, None)
                    if runtime_obj is not None:
                        import types

                        if isinstance(runtime_obj, types.ModuleType):
                            failed_exports[name] = "submodule (excluded from top-level docs)"
                            continue

                if quartodoc_get_object is not None:
                    try:
                        # Try to load the object exactly as quartodoc would
                        qd_obj = quartodoc_get_object(f"{normalized_name}:{name}")
                        # Try to access members to trigger any lazy resolution errors
                        _ = qd_obj.members
                        _ = qd_obj.kind
                        safe_exports.append(name)
                    except griffe.CyclicAliasError:
                        failed_exports[name] = "cyclic alias"
                    except griffe.AliasResolutionError:
                        failed_exports[name] = "unresolvable alias"
                    except KeyError:
                        failed_exports[name] = "not found (likely Rust/PyO3)"
                    except Exception as e:
                        # Catch-all for any other error that would crash quartodoc
                        failed_exports[name] = f"{type(e).__name__}"
                else:
                    # Fallback: use basic griffe check if quartodoc not available
                    try:
                        obj = pkg.members[name]
                        _ = obj.kind
                        _ = obj.members
                        safe_exports.append(name)
                    except Exception as e:
                        failed_exports[name] = f"{type(e).__name__}"

            # Report excluded items grouped by error type
            if failed_exports:
                # Group by error type for cleaner output
                by_error = {}
                for name, error in failed_exports.items():
                    by_error.setdefault(error, []).append(name)

                for error_type, names in sorted(by_error.items()):
                    print(
                        f"Excluding {len(names)} object(s) ({error_type}): "
                        f"{', '.join(sorted(names))}"
                    )

            return safe_exports

        except ImportError:
            print("Warning: griffe not available, cannot use dir() discovery")
            return None
        except Exception as e:
            print(f"Error discovering exports via dir(): {type(e).__name__}: {e}")
            return None

    def _get_package_exports(self, package_name: str) -> list | None:
        """
        Get package exports using the configured discovery method.

        By default, uses dir() to discover public objects. If `discovery_method`
        is set to "all" in [tool.great-docs], uses __all__ instead.

        Parameters
        ----------
        package_name
            The name of the package to get exports from.

        Returns
        -------
        list | None
            List of exported/public names, or None if discovery failed.
        """
        metadata = self._get_package_metadata()
        discovery_method = metadata.get("discovery_method", "dir")

        if discovery_method == "all":
            print("Using __all__ discovery method (configured in pyproject.toml)")
            return self._parse_package_exports(package_name)
        else:
            print("Using griffe introspection discovery method (default)")
            exports = self._discover_package_exports(package_name)
            if exports is None:
                print("Falling back to __all__ discovery method")
                return self._parse_package_exports(package_name)
            return exports

    def _categorize_api_objects(self, package_name: str, exports: list) -> dict:
        """
        Categorize API objects using griffe introspection.

        Uses griffe (quartodoc's introspection library) to analyze the package
        structure without importing it. This is safer and works with packages
        that have non-Python components (e.g., Rust bindings).

        Parameters
        ----------
        package_name
            The name of the package.
        exports
            List of exported names from __all__.

        Returns
        -------
        dict
            Dictionary with:
            - classes: list of class names
            - functions: list of function names
            - other: list of other object names
            - class_methods: dict mapping class name to method count
            - class_method_names: dict mapping class name to list of method names
        """
        try:
            import griffe

            # Load the package using griffe
            normalized_name = package_name.replace("-", "_")

            # Try to use quartodoc's get_object for validation
            quartodoc_get_object = None
            try:
                from functools import partial

                from quartodoc import get_object as qd_get_object

                quartodoc_get_object = partial(qd_get_object, dynamic=True, parser="numpy")
            except ImportError:
                pass

            # Try to load the package with griffe
            try:
                pkg = griffe.load(normalized_name)
            except Exception as e:
                print(f"Warning: Could not load package with griffe ({type(e).__name__})")
                # Fallback to simple categorization
                skip_names = {"__version__", "__author__", "__email__", "__all__"}
                filtered_exports = [e for e in exports if e not in skip_names]
                return {
                    "classes": [],
                    "functions": [],
                    "other": filtered_exports,
                    "class_methods": {},
                    "class_method_names": {},
                }

            categories = {
                "classes": [],
                "functions": [],
                "other": [],
                "class_methods": {},
                "class_method_names": {},
            }
            failed_introspection = []
            cyclic_aliases = []

            # Skip common metadata variables
            skip_names = {"__version__", "__author__", "__email__", "__all__"}

            for name in exports:
                # Skip metadata variables
                if name in skip_names:
                    continue

                try:
                    # Get the object from the loaded package
                    if name not in pkg.members:
                        categories["other"].append(name)
                        failed_introspection.append(name)
                        continue

                    obj = pkg.members[name]

                    # Categorize based on griffe's kind
                    # Note: Accessing obj.kind or obj.members on an Alias can trigger
                    # resolution which may raise CyclicAliasError or AliasResolutionError
                    if obj.kind.value == "class":
                        categories["classes"].append(name)
                        # Get public methods (exclude private/magic methods)
                        # We need to handle each member individually to catch cyclic aliases
                        # AND validate each method with quartodoc to catch type hint issues
                        # Collect (method_name, lineno) tuples to preserve source order
                        method_entries = []
                        skipped_methods = []
                        try:
                            for member_name, member in obj.members.items():
                                if member_name.startswith("_"):
                                    continue
                                try:
                                    # Accessing member.kind can trigger alias resolution
                                    if member.kind.value in ("function", "method"):
                                        # Get line number for source ordering
                                        lineno = getattr(member, "lineno", float("inf"))
                                        # Validate with quartodoc if available
                                        if quartodoc_get_object is not None:
                                            try:
                                                qd_obj = quartodoc_get_object(
                                                    f"{normalized_name}:{name}.{member_name}"
                                                )
                                                # Try to access properties that might fail
                                                _ = qd_obj.members
                                                _ = qd_obj.kind
                                                method_entries.append((member_name, lineno))
                                            except Exception:
                                                # Method can't be documented by quartodoc
                                                skipped_methods.append(member_name)
                                        else:
                                            method_entries.append((member_name, lineno))
                                except (
                                    griffe.CyclicAliasError,
                                    griffe.AliasResolutionError,
                                ):
                                    # Skip cyclic/unresolvable class members
                                    skipped_methods.append(member_name)
                                except Exception:
                                    # Skip members that can't be introspected
                                    pass
                        except (griffe.CyclicAliasError, griffe.AliasResolutionError):
                            # If we can't even iterate members, class has issues
                            skipped_methods.append("<members>")

                        # Sort by line number to preserve source file order
                        method_entries.sort(key=lambda x: x[1])
                        method_names = [entry[0] for entry in method_entries]

                        if skipped_methods:
                            print(
                                f"  {name}: class with {len(method_names)} public methods "
                                f"(skipped {len(skipped_methods)} undocumentable method(s): "
                                f"{', '.join(skipped_methods[:3])}{'...' if len(skipped_methods) > 3 else ''})"
                            )
                        else:
                            print(f"  {name}: class with {len(method_names)} public methods")

                        categories["class_methods"][name] = len(method_names)
                        categories["class_method_names"][name] = method_names
                    elif obj.kind.value == "function":
                        categories["functions"].append(name)
                    else:
                        # Attributes, modules, etc.
                        categories["other"].append(name)

                except griffe.CyclicAliasError:
                    # Cyclic alias detected (e.g., re-exported symbol pointing to itself)
                    # This can happen with complex re-export patterns
                    # Do NOT add to categories (these must be excluded entirely)
                    print(f"  Warning: Cyclic alias detected for '{name}', excluding from docs")
                    cyclic_aliases.append(name)
                except griffe.AliasResolutionError:
                    # Alias could not be resolved (target not found)
                    # Do NOT add to categories (these must be excluded entirely)
                    print(f"  Warning: Could not resolve alias for '{name}', excluding from docs")
                    failed_introspection.append(name)
                except Exception as e:
                    # If introspection fails for a specific object, still include it
                    print(f"  Warning: Could not introspect '{name}': {type(e).__name__}")
                    categories["other"].append(name)
                    failed_introspection.append(name)

            if cyclic_aliases:
                print(f"Note: Excluded {len(cyclic_aliases)} cyclic alias(es) from documentation")

            if failed_introspection:
                print(
                    f"Note: Could not introspect {len(failed_introspection)} item(s), categorizing as 'Other'"
                )

            return categories

        except ImportError:
            print("Warning: griffe not available, using fallback categorization")
            # Fallback if griffe isn't installed
            skip_names = {"__version__", "__author__", "__email__", "__all__"}
            filtered_exports = [e for e in exports if e not in skip_names]
            return {
                "classes": [],
                "functions": [],
                "other": filtered_exports,
                "class_methods": {},
                "class_method_names": {},
            }

    def _create_quartodoc_sections(self, package_name: str) -> list | None:
        """
        Create quartodoc sections based on discovered package exports.

        Uses the configured discovery method (dir() by default, or __all__ if specified).

        Uses smart heuristics:
        - Classes with â‰¤5 methods: documented inline
        - Classes with >5 methods: separate pages for each method

        Parameters
        ----------
        package_name
            The name of the package.

        Returns
        -------
        list | None
            List of section dictionaries, or None if no sections could be created.
        """
        exports = self._get_package_exports(package_name)
        if not exports:
            return None

        # Filter out metadata variables at the export level too
        skip_names = {"__version__", "__author__", "__email__", "__all__"}
        exports = [e for e in exports if e not in skip_names]

        if not exports:
            return None

        print(f"Found {len(exports)} exported names to document")

        # Categorize the exports
        categories = self._categorize_api_objects(package_name, exports)

        sections = []

        # Add classes section if there are any
        if categories["classes"]:
            class_contents = []
            classes_with_separate_methods = []

            for class_name in categories["classes"]:
                method_count = categories["class_methods"].get(class_name, 0)

                if method_count > 5:
                    # Class with many methods: add with members: [] to suppress inline docs
                    class_contents.append({"name": class_name, "members": []})
                    classes_with_separate_methods.append(class_name)
                else:
                    # Class with few methods: document inline
                    class_contents.append(class_name)

            sections.append(
                {
                    "title": "Classes",
                    "desc": "Core classes and types",
                    "contents": class_contents,
                }
            )

            # Create separate sections for methods of large classes
            for class_name in classes_with_separate_methods:
                method_names = categories["class_method_names"].get(class_name, [])
                method_count = len(method_names)

                # Create fully qualified method references
                method_contents = [f"{class_name}.{method}" for method in method_names]

                sections.append(
                    {
                        "title": f"{class_name} Methods",
                        "desc": f"Methods for the {class_name} class",
                        "contents": method_contents,
                    }
                )

                print(f"  Created separate section for {class_name} with {method_count} methods")

        # Add functions section if there are any
        if categories["functions"]:
            sections.append(
                {
                    "title": "Functions",
                    "desc": "Public functions",
                    "contents": categories["functions"],
                }
            )

        # Add other exports section if there are any
        if categories["other"]:
            sections.append(
                {"title": "Other", "desc": "Additional exports", "contents": categories["other"]}
            )

        return sections if sections else None

    def _extract_all_directives(self, package_name: str) -> dict:
        """
        Extract Great Docs directives from all docstrings in the package.

        Scans all exported classes, methods, and functions for @family, @order,
        @seealso, and @nodoc directives.

        Parameters
        ----------
        package_name
            The name of the package to scan.

        Returns
        -------
        dict
            Mapping of object names to their DocDirectives.
            Keys are either simple names (e.g., "MyClass") or qualified names
            (e.g., "MyClass.my_method").
        """
        from ._directives import extract_directives

        try:
            import griffe

            normalized_name = package_name.replace("-", "_")

            try:
                pkg = griffe.load(normalized_name)
            except Exception as e:
                print(f"Warning: Could not load package with griffe ({type(e).__name__})")
                return {}

            directive_map = {}

            for name, obj in pkg.members.items():
                # Skip private members
                if name.startswith("_"):
                    continue

                # Extract directives from the object's docstring
                if obj.docstring:
                    directives = extract_directives(obj.docstring.value)
                    if directives:
                        directive_map[name] = directives

                # For classes, also process methods
                try:
                    if obj.kind.value == "class":
                        for method_name, method in obj.members.items():
                            if method_name.startswith("_"):
                                continue
                            if method.docstring:
                                method_directives = extract_directives(method.docstring.value)
                                if method_directives:
                                    directive_map[f"{name}.{method_name}"] = method_directives
                except Exception:
                    # Skip if we can't introspect the class
                    pass

            return directive_map

        except ImportError:
            print("Warning: griffe not available for directive extraction")
            return {}
        except Exception as e:
            print(f"Error extracting directives: {type(e).__name__}: {e}")
            return {}

    def _get_family_config(self) -> dict:
        """
        Get family configuration from pyproject.toml.

        Returns
        -------
        dict
            Family configuration with titles, descriptions, and ordering.
        """
        metadata = self._get_package_metadata()
        return metadata.get("families", {})

    def _auto_title(self, family_name: str) -> str:
        """
        Generate a display title from a family name.

        Converts kebab-case or snake_case to Title Case.

        Parameters
        ----------
        family_name
            The family name (e.g., "family-name" or "family_name").

        Returns
        -------
        str
            Title-cased name (e.g., "Family Name").
        """
        # Replace hyphens and underscores with spaces, then title case
        return family_name.replace("-", " ").replace("_", " ").title()

    def _normalize_family_key(self, family_name: str) -> str:
        """
        Normalize a family name to a configuration key.

        Converts "Family Name" -> "family-name" for config lookup.

        Parameters
        ----------
        family_name
            The family name as written in the docstring.

        Returns
        -------
        str
            Normalized key for configuration lookup.
        """
        return family_name.lower().replace(" ", "-").replace("_", "-")

    def _create_quartodoc_sections_from_families(self, package_name: str) -> list | None:
        """
        Create quartodoc sections based on @family directives in docstrings.

        This method scans all docstrings for @family, @order, and @nodoc directives
        and generates organized sections. Items without @family directives are
        placed in auto-generated categories (Classes, Functions, Other).

        Parameters
        ----------
        package_name
            The name of the package.

        Returns
        -------
        list | None
            List of section dictionaries organized by family, or None if
            no exports found.
        """
        from ._directives import DocDirectives

        exports = self._get_package_exports(package_name)
        if not exports:
            return None

        # Filter out metadata variables
        skip_names = {"__version__", "__author__", "__email__", "__all__"}
        exports = [e for e in exports if e not in skip_names]

        if not exports:
            return None

        # Extract directives from all docstrings
        directive_map = self._extract_all_directives(package_name)

        # Get family configuration from pyproject.toml
        family_config = self._get_family_config()

        # Categorize exports for fallback (items without @family)
        categories = self._categorize_api_objects(package_name, exports)

        # Build family map: family_name -> list of items
        family_map: dict[str, list[dict]] = {}
        items_with_family: set[str] = set()

        # Process top-level exports
        for item_name in exports:
            directives = directive_map.get(item_name, DocDirectives())

            # Skip items marked @nodoc
            if directives.nodoc:
                print(f"  Excluding '{item_name}' (@nodoc)")
                continue

            if directives.family:
                family = directives.family
                if family not in family_map:
                    family_map[family] = []

                # Determine if this is a class with methods
                is_class = item_name in categories.get("classes", [])
                method_count = categories.get("class_methods", {}).get(item_name, 0)

                family_map[family].append(
                    {
                        "name": item_name,
                        "order": directives.order if directives.order is not None else 999,
                        "seealso": directives.seealso,
                        "is_class": is_class,
                        "method_count": method_count,
                    }
                )
                items_with_family.add(item_name)

        # Process class methods that might have their own @family
        for class_name in categories.get("classes", []):
            method_names = categories.get("class_method_names", {}).get(class_name, [])
            for method_name in method_names:
                full_name = f"{class_name}.{method_name}"
                directives = directive_map.get(full_name, DocDirectives())

                if directives.nodoc:
                    continue

                if directives.family:
                    family = directives.family
                    if family not in family_map:
                        family_map[family] = []

                    family_map[family].append(
                        {
                            "name": full_name,
                            "order": directives.order if directives.order is not None else 999,
                            "seealso": directives.seealso,
                            "is_class": False,
                            "method_count": 0,
                        }
                    )
                    items_with_family.add(full_name)

        # If no families found, fall back to default categorization
        if not family_map:
            print("No @family directives found, using default categorization")
            return self._create_quartodoc_sections(package_name)

        print(f"Found {len(family_map)} family group(s) from @family directives")

        # Build sections from families
        sections = []

        # Sort families by their configured order, then alphabetically
        def family_sort_key(family_name: str) -> tuple:
            config_key = self._normalize_family_key(family_name)
            config = family_config.get(config_key, {})
            order = config.get("order", 999)
            return (order, family_name.lower())

        sorted_families = sorted(family_map.keys(), key=family_sort_key)

        for family_name in sorted_families:
            items = family_map[family_name]

            # Sort items by order, then alphabetically
            items.sort(key=lambda x: (x["order"], x["name"].lower()))

            # Get display name and description from config
            config_key = self._normalize_family_key(family_name)
            config = family_config.get(config_key, {})
            title = config.get("title", family_name)  # Use family name as-is if no config
            desc = config.get("desc", "")

            # Format contents for quartodoc
            contents = []
            for item in items:
                name = item["name"]
                if item["is_class"] and item["method_count"] > 5:
                    # Large class: suppress inline method docs
                    contents.append({"name": name, "members": []})
                else:
                    contents.append(name)

            sections.append(
                {
                    "title": title,
                    "desc": desc,
                    "contents": contents,
                }
            )

            print(f"  {title}: {len(items)} item(s)")

        # Add items without @family to fallback sections
        unassigned_classes = [
            c for c in categories.get("classes", []) if c not in items_with_family
        ]
        unassigned_functions = [
            f for f in categories.get("functions", []) if f not in items_with_family
        ]
        unassigned_other = [o for o in categories.get("other", []) if o not in items_with_family]

        if unassigned_classes:
            class_contents = []
            for class_name in unassigned_classes:
                method_count = categories.get("class_methods", {}).get(class_name, 0)
                if method_count > 5:
                    class_contents.append({"name": class_name, "members": []})
                else:
                    class_contents.append(class_name)

            sections.append(
                {
                    "title": "Classes",
                    "desc": "Core classes and types",
                    "contents": class_contents,
                }
            )
            print(f"  Classes (unassigned): {len(unassigned_classes)} item(s)")

        if unassigned_functions:
            sections.append(
                {
                    "title": "Functions",
                    "desc": "Public functions",
                    "contents": unassigned_functions,
                }
            )
            print(f"  Functions (unassigned): {len(unassigned_functions)} item(s)")

        if unassigned_other:
            sections.append(
                {
                    "title": "Other",
                    "desc": "Additional exports",
                    "contents": unassigned_other,
                }
            )
            print(f"  Other (unassigned): {len(unassigned_other)} item(s)")

        return sections if sections else None

    def _find_index_source_file(self) -> tuple[Path | None, list[str]]:
        """
        Find the best source file for index.qmd based on priority.

        Priority order (highest to lowest):
        1. index.qmd in project root
        2. index.md in project root
        3. README.md in project root

        Returns
        -------
        tuple[Path | None, list[str]]
            A tuple of (source_file_path, warnings_list).
            source_file_path is None if no suitable file is found.
        """
        package_root = self._find_package_root()
        warnings = []

        index_qmd_root = package_root / "index.qmd"
        index_md_root = package_root / "index.md"
        readme_path = package_root / "README.md"

        # Check which files exist
        has_index_qmd = index_qmd_root.exists()
        has_index_md = index_md_root.exists()
        has_readme = readme_path.exists()

        # Generate warnings for multiple source files
        if has_index_qmd and (has_index_md or has_readme):
            other_files = []
            if has_index_md:
                other_files.append("index.md")
            if has_readme:
                other_files.append("README.md")
            warnings.append(
                f"âš ï¸  Multiple index source files detected. Using index.qmd "
                f"(ignoring {', '.join(other_files)})"
            )
            return index_qmd_root, warnings

        if has_index_md and has_readme:
            warnings.append(
                "âš ï¸  Multiple index source files detected. Using index.md (ignoring README.md)"
            )
            return index_md_root, warnings

        # Return based on priority
        if has_index_qmd:
            return index_qmd_root, warnings
        if has_index_md:
            return index_md_root, warnings
        if has_readme:
            return readme_path, warnings

        return None, warnings

    def _create_index_from_readme(self, force_rebuild: bool = False) -> None:
        """
        Create or update index.qmd from the best available source file.

        Source file priority (highest to lowest):
        1. index.qmd in project root
        2. index.md in project root
        3. README.md in project root

        This mimics pkgdown's behavior of using the README as the homepage.
        Includes a metadata sidebar with package information (license, authors, links, etc.)

        Parameters
        ----------
        force_rebuild
            If True, always rebuild index.qmd even if it exists.
            Used by the build command to sync with source file changes.
        """
        package_root = self._find_package_root()

        # Always create license.qmd if LICENSE file exists
        license_path = package_root / "LICENSE"
        license_link = None
        if license_path.exists():
            license_qmd = self.project_path / "license.qmd"
            with open(license_path, "r", encoding="utf-8") as f:
                license_content = f.read()

            license_qmd_content = f"""---
title: "License"
---

```
{license_content}
```
"""
            with open(license_qmd, "w", encoding="utf-8") as f:
                f.write(license_qmd_content)
            print(f"Created {license_qmd}")
            license_link = "license.qmd"

        # Always create citation.qmd if CITATION.cff exists
        citation_path = package_root / "CITATION.cff"
        citation_link = None
        if citation_path.exists():
            citation_qmd = self.project_path / "citation.qmd"

            # Get metadata first to access rich_authors
            metadata = self._get_package_metadata()

            # Parse CITATION.cff for structured data
            import yaml

            with open(citation_path, "r", encoding="utf-8") as f:
                citation_data = yaml.safe_load(f)

            # Build Authors section
            authors_section = "## Authors\n\n"
            if citation_data.get("authors"):
                for author in citation_data["authors"]:
                    given = author.get("given-names", "")
                    family = author.get("family-names", "")
                    full_name = f"{given} {family}".strip()

                    # Get role from rich_authors if available
                    role = "Author"
                    if metadata.get("rich_authors"):
                        for rich_author in metadata["rich_authors"]:
                            if rich_author.get("name") == full_name:
                                role = rich_author.get("role", "Author")
                                break

                    authors_section += f"{full_name}. {role}.  \n"

            # Build Citation section with text and BibTeX
            citation_section = "## Citation\n\n"
            citation_section += "**Source:** `CITATION.cff`\n\n"

            # Generate text citation
            if citation_data.get("authors"):
                author_names = []
                for author in citation_data["authors"]:
                    family = author.get("family-names", "")
                    given = author.get("given-names", "")
                    initial = given[0] if given else ""
                    author_names.append(f"{family} {initial}" if initial else family)

                authors_str = ", ".join(author_names)
                title = citation_data.get("title", "")
                version = citation_data.get("version", "")
                url = citation_data.get("url", "")
                year = "2025"  # Could parse from date-released if available

                citation_section += (
                    f"{authors_str} ({year}). {title} Python package version {version}, {url}.\n\n"
                )

            # Generate BibTeX
            citation_section += "```bibtex\n"
            citation_section += "@Manual{,\n"

            if citation_data.get("title"):
                citation_section += f"  title = {{{citation_data['title']}}},\n"

            if citation_data.get("authors"):
                author_names = []
                for author in citation_data["authors"]:
                    given = author.get("given-names", "")
                    family = author.get("family-names", "")
                    full_name = f"{given} {family}".strip()
                    author_names.append(full_name)
                citation_section += f"  author = {{{' and '.join(author_names)}}},\n"

            citation_section += "  year = {2025},\n"

            if citation_data.get("version"):
                citation_section += (
                    f"  note = {{Python package version {citation_data['version']}}},\n"
                )

            if citation_data.get("url"):
                citation_section += f"  url = {{{citation_data['url']}}},\n"

            citation_section += "}\n```\n"

            citation_qmd_content = f"""---
title: "Authors and Citation"
---

{authors_section}

{citation_section}
"""
            with open(citation_qmd, "w", encoding="utf-8") as f:
                f.write(citation_qmd_content)
            print(f"Created {citation_qmd}")
            citation_link = "citation.qmd"

        # Now check if we should create index.qmd
        index_qmd = self.project_path / "index.qmd"

        if index_qmd.exists() and not force_rebuild:
            print("index.qmd already exists, skipping creation")
            return

        # Find the best source file
        source_file, warnings = self._find_index_source_file()

        # Print any warnings about multiple source files
        for warning in warnings:
            print(warning)

        if source_file is None:
            print(
                "No index source file found (index.qmd, index.md, or README.md), skipping index.qmd creation"
            )
            return

        source_name = source_file.name
        if force_rebuild:
            print(f"Rebuilding index.qmd from {source_name}...")
        else:
            print(f"Creating index.qmd from {source_name}...")

        # Read source content
        with open(source_file, "r", encoding="utf-8") as f:
            readme_content = f.read()

        # Adjust heading levels: bump all headings up by one level
        # This prevents h1 from becoming paragraphs and keeps proper hierarchy
        # Replace headings from highest to lowest level to avoid double-replacement
        import re

        readme_content = re.sub(r"^######\s+", r"####### ", readme_content, flags=re.MULTILINE)
        readme_content = re.sub(r"^#####\s+", r"###### ", readme_content, flags=re.MULTILINE)
        readme_content = re.sub(r"^####\s+", r"##### ", readme_content, flags=re.MULTILINE)
        readme_content = re.sub(r"^###\s+", r"#### ", readme_content, flags=re.MULTILINE)
        readme_content = re.sub(r"^##\s+", r"### ", readme_content, flags=re.MULTILINE)
        readme_content = re.sub(r"^#\s+", r"## ", readme_content, flags=re.MULTILINE)

        # Get package metadata for sidebar
        metadata = self._get_package_metadata()

        # Build margin content sections (right sidebar)
        margin_sections = []

        # Links section
        links_added = []

        # Try to add PyPI link based on package name
        package_name = self._detect_package_name()
        if package_name:
            pypi_url = f"https://pypi.org/project/{package_name}/"
            margin_sections.append("#### Links\n")
            margin_sections.append(f"[View on PyPI]({pypi_url})<br>")
            links_added.append("pypi")

        if metadata.get("urls"):
            if not links_added:
                margin_sections.append("#### Links\n")

            urls = metadata["urls"]

            # Map common URL names to display text
            url_map = {
                "homepage": None,  # Skip if we already added PyPI
                "repository": "Browse source code",
                "bug_tracker": "Report a bug",
                "documentation": None,  # Skip for that's the site we're on
            }

            for name, url in urls.items():
                name_lower = name.lower().replace(" ", "_")
                display_name = url_map.get(name_lower, name.replace("_", " ").title())

                # Skip if display_name is None (homepage/documentation)
                if display_name:
                    margin_sections.append(f"[{display_name}]({url})<br>")

        # Add llms.txt link at the end of Links section
        if links_added or metadata.get("urls"):
            margin_sections.append("[llms.txt](llms.txt)<br>")
        else:
            # If no links section exists yet, create one just for llms.txt
            margin_sections.append("#### Links\n")
            margin_sections.append("[llms.txt](llms.txt)<br>")

        # License section
        if license_link:
            margin_sections.append("\n#### License\n")
            margin_sections.append(f"[Full license]({license_link})<br>")
        elif metadata.get("license"):
            margin_sections.append("\n#### License\n")
            margin_sections.append(f"{metadata['license']}")

        # Community section - check for CONTRIBUTING.md and CODE_OF_CONDUCT.md
        community_items = []

        # Check for CONTRIBUTING.md in root or .github directory
        contributing_path = package_root / "CONTRIBUTING.md"
        if not contributing_path.exists():
            contributing_path = package_root / ".github" / "CONTRIBUTING.md"

        # Check for CODE_OF_CONDUCT.md in root or .github directory
        coc_path = package_root / "CODE_OF_CONDUCT.md"
        if not coc_path.exists():
            coc_path = package_root / ".github" / "CODE_OF_CONDUCT.md"

        if contributing_path.exists():
            community_items.append("[Contributing guide](contributing.qmd)<br>")
            # Create contributing.qmd
            with open(contributing_path, "r", encoding="utf-8") as f:
                contributing_content = f.read()

            # Strip first heading if it exists to avoid duplication with title
            lines = contributing_content.split("\n")
            if lines and lines[0].startswith("# "):
                contributing_content = "\n".join(lines[1:]).lstrip()

            contributing_qmd = self.project_path / "contributing.qmd"
            contributing_qmd_content = f"""---
title: "Contributing"
---

{contributing_content}
"""
            with open(contributing_qmd, "w", encoding="utf-8") as f:
                f.write(contributing_qmd_content)
            print(f"Created {contributing_qmd}")

        if coc_path.exists():
            community_items.append("[Code of conduct](code-of-conduct.qmd)<br>")
            # Create code-of-conduct.qmd
            with open(coc_path, "r", encoding="utf-8") as f:
                coc_content = f.read()

            # Strip first heading if it exists to avoid duplication with title
            lines = coc_content.split("\n")
            if lines and lines[0].startswith("# "):
                coc_content = "\n".join(lines[1:]).lstrip()

            coc_qmd = self.project_path / "code-of-conduct.qmd"
            coc_qmd_content = f"""---
title: "Code of Conduct"
---

{coc_content}
"""
            with open(coc_qmd, "w", encoding="utf-8") as f:
                f.write(coc_qmd_content)
            print(f"Created {coc_qmd}")

        if community_items:
            margin_sections.append("\n#### Community\n")
            margin_sections.extend(community_items)

        # Developers section (Authors)
        # Use rich author metadata if available, otherwise fall back to standard authors
        authors_to_display = metadata.get("rich_authors") or metadata.get("authors", [])

        if authors_to_display:
            margin_sections.append("\n#### Developers\n")

            # Try to extract GitHub username from repository URL as fallback
            fallback_github = None
            if metadata.get("urls"):
                repo_url = metadata["urls"].get("repository", "") or metadata["urls"].get(
                    "Repository", ""
                )
                if "github.com/" in repo_url:
                    # Extract username from URL like https://github.com/username/repo
                    parts = repo_url.rstrip("/").split("github.com/")
                    if len(parts) > 1:
                        username_part = parts[1].split("/")[0]
                        if username_part:
                            fallback_github = username_part

            for idx, author in enumerate(authors_to_display):
                if isinstance(author, dict):
                    name = author.get("name", "")
                    email = author.get("email", "")

                    # Rich metadata fields (from tool.great-docs.authors)
                    role = author.get("role", "")
                    affiliation = author.get("affiliation", "")
                    github = author.get("github", "")
                    homepage = author.get("homepage", "")
                    orcid = author.get("orcid", "")

                    # Build author line with name
                    author_parts = [f"**{name}**" if role else name]

                    # Add role/affiliation on separate lines if available
                    if role:
                        author_parts.append(f"<br><small>{role}</small>")
                    if affiliation:
                        author_parts.append(
                            f'<br><small style="margin-top: -0.15em; display: block;">{affiliation}</small>'
                        )

                    # Add icon links
                    icon_links = []

                    if email:
                        icon_links.append(
                            f'<a href="mailto:{email}" title="Email"><i class="bi bi-envelope-fill"></i></a>'
                        )

                    if github:
                        icon_links.append(
                            f'<a href="https://github.com/{github}" title="GitHub"><i class="bi bi-github"></i></a>'
                        )
                    elif fallback_github:
                        icon_links.append(
                            f'<a href="https://github.com/{fallback_github}" title="GitHub"><i class="bi bi-github"></i></a>'
                        )

                    if homepage:
                        icon_links.append(
                            f'<a href="{homepage}" title="Homepage"><i class="bi bi-house-fill"></i></a>'
                        )

                    if orcid:
                        # ORCID should be a full URL or just the ID
                        orcid_url = (
                            orcid if orcid.startswith("http") else f"https://orcid.org/{orcid}"
                        )
                        icon_links.append(
                            f'<a href="{orcid_url}" title="ORCID"><i class="fa-brands fa-orcid"></i></a>'
                        )

                    if icon_links:
                        author_parts.append(
                            '<span style="margin-top: -0.15em; display: block;">'
                            + " ".join(icon_links)
                            + "</span>"
                        )

                    # Wrap in <p> tag with padding for non-first authors
                    author_content = " ".join(author_parts)
                    if idx == 0:
                        margin_sections.append(f"<p>{author_content}</p>")
                    else:
                        margin_sections.append(
                            f'<p style="padding-top: 10px;">{author_content}</p>'
                        )

        # Meta section (Python version and extras)
        meta_items = []
        if metadata.get("requires_python"):
            meta_items.append(f"**Requires:** Python `{metadata['requires_python']}`")

        if metadata.get("optional_dependencies"):
            extras = list(metadata["optional_dependencies"].keys())
            if extras:
                # Wrap each extra in backticks for monospace
                extras_formatted = ", ".join(f"`{extra}`" for extra in extras)
                meta_items.append(f"**Provides-Extra:** {extras_formatted}")

        if meta_items:
            margin_sections.append("\n#### Meta\n")
            margin_sections.append("<br>\n".join(meta_items))

        # Citation section (if CITATION.cff exists)
        if citation_link:
            margin_sections.append("\n#### Citation\n")
            margin_sections.append(f"[Citing great-docs]({citation_link})")

        # Build margin content
        margin_content = "\n".join(margin_sections) if margin_sections else ""

        # CSS to reduce top margin of first heading element
        # The heading ends up inside a section.level1 > h1 structure
        first_heading_style = """<style>
section.level1:first-of-type > h1:first-child,
section.level2:first-of-type > h2:first-child,
.column-body-outset-right > section.level1:first-of-type > h1,
#quarto-document-content > section:first-of-type > h1 {
  margin-top: 4px !important;
}
</style>

"""

        # Create a qmd file with the README content
        # Use empty title so "Home" doesn't appear on landing page
        # Add margin content in a special div that Quarto will place in the margin
        if margin_content:
            qmd_content = f"""---
title: ""
toc: false
---

{first_heading_style}::: {{.column-margin}}
{margin_content}
:::

{readme_content}
"""
        else:
            qmd_content = f"""---
title: ""
toc: false
---

{first_heading_style}{readme_content}
"""

        with open(index_qmd, "w", encoding="utf-8") as f:
            f.write(qmd_content)

        print(f"Created {index_qmd}")

    def _add_quartodoc_config(self) -> None:
        """
        Add quartodoc configuration to _quarto.yml if not present.

        Adds sensible defaults for quartodoc with automatic package detection.
        """
        quarto_yml = self.project_path / "_quarto.yml"

        with open(quarto_yml, "r") as f:
            config = yaml.safe_load(f) or {}

        # Check if quartodoc config already exists
        if "quartodoc" in config:
            print("quartodoc configuration already exists, skipping")
            return

        # Detect package name
        package_name = self._detect_package_name()

        if not package_name:
            response = input(
                "\nCould not auto-detect package name. Enter package name for quartodoc (or press Enter to skip): "
            ).strip()
            if not response:
                print("Skipping quartodoc configuration")
                return
            package_name = response

        print(f"Adding quartodoc configuration for package: {package_name}")

        # Convert package name to importable form (hyphens -> underscores)
        importable_name = self._normalize_package_name(package_name)

        # Try to auto-generate sections from discovered exports
        # First try family-based organization (from @family directives)
        # Falls back to default categorization if no directives found
        sections = self._create_quartodoc_sections_from_families(importable_name)

        # Add quartodoc configuration with sensible defaults
        # Use the importable name (with underscores) for the package field
        quartodoc_config = {
            "package": importable_name,
            "dir": "reference",
            "title": "API Reference",
            "style": "pkgdown",
            "dynamic": True,
            "renderer": {"style": "markdown", "table_style": "description-list"},
        }

        # Add sections if we found them
        if sections:
            quartodoc_config["sections"] = sections
            print(f"Auto-generated {len(sections)} section(s) from package exports")
        else:
            print("Could not auto-generate sections from package exports")
            print("You'll need to manually add sections to organize your API documentation.")

        config["quartodoc"] = quartodoc_config

        # Write back to file
        with open(quarto_yml, "w") as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False)

        print(f"Added quartodoc configuration to {quarto_yml}")
        if not sections:
            print("See: https://machow.github.io/quartodoc/get-started/overview.html")

    def _refresh_quartodoc_config(self) -> None:
        """
        Refresh the quartodoc sections in _quarto.yml based on current package exports.

        This method re-discovers the package API and updates the quartodoc sections
        without touching other configuration. Use this when your package API has changed
        (new classes, methods, or functions added/removed).

        The method preserves:
        - Package name and other quartodoc settings
        - All non-quartodoc configuration in _quarto.yml

        Only the 'sections' key in quartodoc config is regenerated.
        """
        quarto_yml = self.project_path / "_quarto.yml"

        if not quarto_yml.exists():
            print("Error: _quarto.yml not found. Run 'great-docs init' first.")
            return

        with open(quarto_yml, "r") as f:
            config = yaml.safe_load(f) or {}

        if "quartodoc" not in config:
            print("Error: No quartodoc configuration found. Run 'great-docs init' first.")
            return

        # Get the package name from existing config
        package_name = config["quartodoc"].get("package")
        if not package_name:
            print("Error: No package name in quartodoc config.")
            return

        print(f"Re-discovering exports for package: {package_name}")

        # Re-generate sections from current package exports
        # Uses family-based organization if @family directives are found
        sections = self._create_quartodoc_sections_from_families(package_name)

        if sections:
            config["quartodoc"]["sections"] = sections
            print(f"Updated quartodoc config with {len(sections)} section(s)")

            # Also update the sidebar to match the new sections
            self._update_sidebar_from_sections()

            # Write back to file
            with open(quarto_yml, "w") as f:
                yaml.dump(config, f, default_flow_style=False, sort_keys=False)

            print(f"âœ… Refreshed quartodoc configuration in {quarto_yml}")
        else:
            print("Warning: Could not discover package exports. Config unchanged.")

    def _update_quarto_config(self) -> None:
        """
        Update _quarto.yml with great-docs configuration.

        This private method modifies the Quarto configuration file to include the
        post-render script, CSS file, and website navigation required by great-docs.
        It preserves existing configuration while adding the necessary great-docs
        settings. If website navigation is not present, it adds a navbar with Home
        and API Reference links, and sets the site title to the package name.
        """
        quarto_yml = self.project_path / "_quarto.yml"

        if not quarto_yml.exists():
            print("Warning: _quarto.yml not found. Creating minimal configuration...")
            config = {
                "project": {"type": "website", "post-render": "scripts/post-render.py"},
                "format": {"html": {"theme": "flatly", "css": ["great-docs.css"]}},
            }
        else:
            # Load existing configuration
            with open(quarto_yml, "r") as f:
                config = yaml.safe_load(f) or {}

        # Ensure required structure exists
        if "project" not in config:
            config["project"] = {}
        if "format" not in config:
            config["format"] = {}
        if "html" not in config["format"]:
            config["format"]["html"] = {}

        # Add post-render script
        config["project"]["post-render"] = "scripts/post-render.py"

        # Add CSS file
        if "css" not in config["format"]["html"]:
            config["format"]["html"]["css"] = []
        elif isinstance(config["format"]["html"]["css"], str):
            config["format"]["html"]["css"] = [config["format"]["html"]["css"]]

        if "great-docs.css" not in config["format"]["html"]["css"]:
            config["format"]["html"]["css"].append("great-docs.css")

        # Ensure flatly theme is used (works well with great-docs)
        if "theme" not in config["format"]["html"]:
            config["format"]["html"]["theme"] = "flatly"

        # Add table of contents configuration for API reference navigation
        if "toc" not in config["format"]["html"]:
            config["format"]["html"]["toc"] = True
        if "toc-depth" not in config["format"]["html"]:
            config["format"]["html"]["toc-depth"] = 2
        if "toc-title" not in config["format"]["html"]:
            config["format"]["html"]["toc-title"] = "On this page"
        if "shift-heading-level-by" not in config["format"]["html"]:
            config["format"]["html"]["shift-heading-level-by"] = -1

        # Add Font Awesome for ORCID icon support
        if "include-in-header" not in config["format"]["html"]:
            config["format"]["html"]["include-in-header"] = []
        elif isinstance(config["format"]["html"]["include-in-header"], str):
            config["format"]["html"]["include-in-header"] = [
                config["format"]["html"]["include-in-header"]
            ]

        # Add Font Awesome CDN if not already present
        fa_cdn = '<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">'
        fa_entry = {"text": fa_cdn}
        if fa_entry not in config["format"]["html"]["include-in-header"]:
            # Check if any Font Awesome link already exists
            has_fa = any(
                "font-awesome" in str(item).lower()
                for item in config["format"]["html"]["include-in-header"]
            )
            if not has_fa:
                config["format"]["html"]["include-in-header"].append(fa_entry)

        # Add website navigation if not present
        if "website" not in config:
            config["website"] = {}

        # Enable page navigation for TOC
        if "page-navigation" not in config["website"]:
            config["website"]["page-navigation"] = True

        # Set title to package name if not already set
        if "title" not in config["website"]:
            package_name = self._detect_package_name()
            if package_name:
                config["website"]["title"] = package_name.title()

        # Add navbar with Home and API Reference links if not present
        if "navbar" not in config["website"]:
            navbar_config = {
                "left": [
                    {"text": "Home", "href": "index.qmd"},
                    {"text": "API Reference", "href": "reference/index.qmd"},
                ]
            }

            # Add GitHub icon link on the right if repository URL is available
            metadata = self._get_package_metadata()
            repo_url = None
            if metadata.get("urls"):
                repo_url = metadata["urls"].get("repository") or metadata["urls"].get("Repository")

            if repo_url and "github.com" in repo_url:
                navbar_config["right"] = [{"icon": "github", "href": repo_url}]

            config["website"]["navbar"] = navbar_config

        # Add sidebar navigation for reference pages
        if "sidebar" not in config["website"]:
            config["website"]["sidebar"] = [
                {
                    "id": "reference",
                    "contents": "reference/",
                }
            ]

        # Add page footer with copyright notice if not present
        if "page-footer" not in config["website"]:
            import datetime

            current_year = datetime.datetime.now().year
            metadata = self._get_package_metadata()

            # Get author name from metadata
            author_name = None
            if metadata.get("authors"):
                first_author = metadata["authors"][0]
                if isinstance(first_author, dict):
                    author_name = first_author.get("name")
                elif isinstance(first_author, str):
                    author_name = first_author

            if author_name:
                config["website"]["page-footer"] = {"left": f"&copy; {current_year} {author_name}"}

        # Write back to file
        with open(quarto_yml, "w") as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False)

        print(f"Updated {quarto_yml} with great-docs configuration")

    def _update_sidebar_from_sections(self) -> None:
        """
        Update sidebar navigation based on quartodoc sections.

        Builds a structured sidebar with sections and their contents,
        and excludes the index page from showing the sidebar.
        """
        quarto_yml = self.project_path / "_quarto.yml"

        if not quarto_yml.exists():
            return

        with open(quarto_yml, "r") as f:
            config = yaml.safe_load(f) or {}

        # Get quartodoc sections if they exist
        if "quartodoc" not in config or "sections" not in config["quartodoc"]:
            return

        sections = config["quartodoc"]["sections"]
        sidebar_contents = []

        # Build sidebar structure from sections
        for section in sections:
            section_entry = {"section": section["title"], "contents": []}

            # Add each item in the section
            for item in section.get("contents", []):
                # Handle both string and dict formats
                if isinstance(item, str):
                    section_entry["contents"].append(f"reference/{item}.qmd")
                elif isinstance(item, dict):
                    # Extract the name from dict format (e.g., {'name': 'Graph', 'members': []})
                    item_name = item.get("name", str(item))
                    section_entry["contents"].append(f"reference/{item_name}.qmd")
                else:
                    # Fallback for unexpected types
                    section_entry["contents"].append(f"reference/{item}.qmd")

            sidebar_contents.append(section_entry)

        # Update sidebar configuration
        if "website" not in config:
            config["website"] = {}

        config["website"]["sidebar"] = [
            {
                "id": "reference",
                "contents": sidebar_contents,
            }
        ]

        # Write back
        with open(quarto_yml, "w") as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False)

    def _update_reference_index_frontmatter(self) -> None:
        """Ensure reference/index.qmd has proper frontmatter."""
        index_path = self.docs_dir / "reference" / "index.qmd"

        if not index_path.exists():
            return

        # Read the current content
        with open(index_path, "r") as f:
            content = f.read()

        # Check if frontmatter already exists - if so, leave it as is
        if content.startswith("---"):
            return

        # Add minimal frontmatter if none exists
        content = f"---\n---\n\n{content}"

        # Write updated content
        with open(index_path, "w") as f:
            f.write(content)

    def _generate_llms_txt(self) -> None:
        """
        Generate an llms.txt file for LLM documentation indexing.

        Creates a structured markdown file that indexes the API reference pages,
        following the llms.txt standard format for LLM-readable documentation.
        The file is saved to the docs directory and will be included in the built site.

        The format follows the structure:
        - Package title with description
        - API Reference section with links to each documented item
        """
        quarto_yml = self.project_path / "_quarto.yml"

        if not quarto_yml.exists():
            return

        with open(quarto_yml, "r") as f:
            config = yaml.safe_load(f) or {}

        # Get quartodoc sections and package info
        if "quartodoc" not in config:
            return

        quartodoc_config = config["quartodoc"]
        sections = quartodoc_config.get("sections", [])
        package_name = quartodoc_config.get("package")

        if not package_name or not sections:
            return

        # Get package metadata for description and site URL
        metadata = self._get_package_metadata()
        description = metadata.get("description", "")

        # Get the site URL - prefer Documentation URL from pyproject.toml,
        # fall back to site-url from _quarto.yml
        urls = metadata.get("urls", {})
        site_url = urls.get("Documentation", "") or config.get("website", {}).get("site-url", "")

        # Clean up site URL - remove any trailing anchors or paths that aren't the base
        if site_url:
            # Remove trailing #readme or similar anchors
            if "#" in site_url:
                site_url = site_url.split("#")[0]
            # Ensure trailing slash
            if not site_url.endswith("/"):
                site_url += "/"

        # Build the llms.txt content
        lines = []

        # Header with package name
        lines.append(f"# {package_name}")
        lines.append("")

        # Description
        if description:
            lines.append(f"> {description}")
            lines.append("")

        # API Reference section
        lines.append("## Docs")
        lines.append("")
        lines.append("### API Reference")
        lines.append("")

        # Process each section
        for section in sections:
            section_title = section.get("title", "")
            section_desc = section.get("desc", "")

            # Add section header as a comment or sub-heading if there are multiple sections
            if len(sections) > 1 and section_title:
                lines.append(f"#### {section_title}")
                if section_desc:
                    lines.append(f"> {section_desc}")
                lines.append("")

            # Add each item in the section
            for item in section.get("contents", []):
                # Handle both string and dict formats
                if isinstance(item, str):
                    item_name = item
                    item_desc = ""
                elif isinstance(item, dict):
                    item_name = item.get("name", str(item))
                    item_desc = ""
                else:
                    continue

                # Get description from docstring if available
                if not item_desc:
                    item_desc = self._get_docstring_summary(package_name, item_name)

                # Build the URL
                if site_url:
                    url = f"{site_url}reference/{item_name}.html"
                else:
                    url = f"reference/{item_name}.html"

                # Format the line
                if item_desc:
                    lines.append(f"- [{item_name}]({url}): {item_desc}")
                else:
                    lines.append(f"- [{item_name}]({url})")

            lines.append("")

        # Write the llms.txt file
        llms_txt_path = self.project_path / "llms.txt"
        with open(llms_txt_path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))

        print(f"Created {llms_txt_path}")

    def _get_docstring_summary(self, package_name: str, item_name: str) -> str:
        """
        Get the first line of a docstring for an item.

        Parameters
        ----------
        package_name
            The name of the package containing the item.
        item_name
            The name of the class, function, or module to get the docstring for.

        Returns
        -------
        str
            The first line of the docstring, or empty string if not available.
        """
        try:
            import importlib

            # Normalize package name
            normalized_name = package_name.replace("-", "_")
            module = importlib.import_module(normalized_name)

            # Try to get the object
            obj = getattr(module, item_name, None)
            if obj is None:
                return ""

            # Get docstring
            docstring = getattr(obj, "__doc__", None)
            if not docstring:
                return ""

            # Extract first line/sentence
            first_line = docstring.strip().split("\n")[0].strip()

            # Clean up the line (remove trailing periods, normalize whitespace)
            first_line = first_line.rstrip(".")

            return first_line

        except Exception:
            return ""

    def uninstall(self) -> None:
        """
        Remove great-docs assets and configuration from the project.

        This method deletes the great-docs CSS file and post-render script,
        and cleans up the `_quarto.yml` configuration file by removing
        great-docs-specific settings.

        Examples
        --------
        Uninstall the docs from the current directory:

        ```python
        from great_docs import GreatDocs

        docs = GreatDocs()
        docs.uninstall()
        ```

        Uninstall from a specific project directory:

        ```python
        docs = GreatDocs("/path/to/my/project")
        docs.uninstall()
        ```

        See Also
        --------
        install : Install great-docs assets and configuration
        """
        print("Uninstalling great-docs from your quartodoc project...")
        print(f"Removing from: {self.project_path.relative_to(self.project_root)}")

        # Remove files
        files_to_remove = [
            self.project_path / "scripts" / "post-render.py",
            self.project_path / "great-docs.css",
            self.project_path / ".gitignore",
        ]

        for file_path in files_to_remove:
            if file_path.exists():
                # For .gitignore, only remove if it matches our template exactly
                if file_path.name == ".gitignore":
                    with open(file_path, "r") as f:
                        content = f.read()
                    # Only remove if it's purely our .gitignore (starts with our comment)
                    if content.strip().startswith("# Quarto build output"):
                        file_path.unlink()
                        print(f"Removed {file_path}")
                    else:
                        print(f"Skipping {file_path} (contains user modifications)")
                else:
                    file_path.unlink()
                    print(f"Removed {file_path}")

        # Clean up _quarto.yml
        self._clean_quarto_config()

        print("âœ… Great-docs uninstalled successfully!")

    def _clean_quarto_config(self) -> None:
        """
        Remove great-docs configuration from _quarto.yml.

        This private method removes the post-render script reference and CSS file
        entry from the Quarto configuration file, reverting it to its pre-installation
        state while preserving other user settings.
        """
        quarto_yml = self.project_path / "_quarto.yml"

        if not quarto_yml.exists():
            return

        with open(quarto_yml, "r") as f:
            config = yaml.safe_load(f) or {}

        # Remove post-render script if it's ours
        if config.get("project", {}).get("post-render") == "scripts/post-render.py":
            del config["project"]["post-render"]

        # Remove CSS file
        css_list = config.get("format", {}).get("html", {}).get("css", [])
        if isinstance(css_list, list) and "great-docs.css" in css_list:
            css_list.remove("great-docs.css")
            if not css_list:
                del config["format"]["html"]["css"]

        # Write back to file
        with open(quarto_yml, "w") as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False)

        print(f"Cleaned great-docs configuration from {quarto_yml}")

    def build(self, watch: bool = False, refresh: bool = True) -> None:
        """
        Build the documentation site.

        Runs quartodoc build followed by quarto render. By default, re-discovers
        package exports and updates the quartodoc configuration before building.

        Parameters
        ----------
        watch
            If True, watch for changes and rebuild automatically.
        refresh
            If True (default), re-discover package exports and update quartodoc
            config before building. Set to False for faster rebuilds when your
            package API hasn't changed.

        Examples
        --------
        Build the documentation (with API refresh):

        ```python
        from great_docs import GreatDocs

        docs = GreatDocs()
        docs.build()
        ```

        Build with watch mode:

        ```python
        docs.build(watch=True)
        ```

        Quick rebuild without API refresh:

        ```python
        docs.build(refresh=False)
        ```
        """
        import subprocess
        import sys
        import threading
        import time

        def show_progress(stop_event, message):
            """Show a simple spinner while command is running."""
            spinner = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
            idx = 0
            while not stop_event.is_set():
                print(f"\r{message} {spinner[idx % len(spinner)]}", end="", flush=True)
                idx += 1
                time.sleep(0.1)
            print(f"\r{message} ", end="", flush=True)

        print("Building documentation with great-docs...")

        # Change to docs directory
        original_dir = os.getcwd()
        try:
            os.chdir(self.project_path)

            # Step 0: Rebuild index.qmd from source file (README.md, index.md, or index.qmd)
            print("\nðŸ“„ Step 0: Syncing landing page with source file...")
            self._create_index_from_readme(force_rebuild=True)

            # Step 0.5: Refresh quartodoc config if requested
            if refresh:
                print("\nðŸ”„ Refreshing quartodoc configuration...")
                self._refresh_quartodoc_config()

            # Step 0.6: Generate llms.txt file
            print("\nðŸ“ Generating llms.txt...")
            self._generate_llms_txt()

            # Step 0.7: Generate source links JSON
            print("\nðŸ”— Generating source links...")
            package_name = self._detect_package_name()
            if package_name:
                self._generate_source_links_json(package_name)

            # Step 1: Run quartodoc build using Python module execution
            # This ensures it uses the same Python environment as great-docs
            print("\nðŸ“š Step 1: Generating API reference with quartodoc...")

            stop_event = threading.Event()
            progress_thread = threading.Thread(
                target=show_progress, args=(stop_event, "   Processing")
            )
            progress_thread.start()

            result = subprocess.run(
                [sys.executable, "-m", "quartodoc", "build"], capture_output=True, text=True
            )

            stop_event.set()
            progress_thread.join()

            if result.returncode != 0:
                print("\nâŒ quartodoc build failed:")
                # Check if quartodoc is not installed
                if "No module named quartodoc" in result.stderr:
                    print("\nâš ï¸  quartodoc is not installed in your environment.")
                    print("\nTo fix this, install quartodoc:")
                    print(f"  {sys.executable} -m pip install quartodoc")
                    print("\nOr if using pip directly:")
                    print("  pip install quartodoc")
                else:
                    print(result.stderr)
                sys.exit(1)
            else:
                print("\nâœ… API reference generated")

            # Step 2: Run quarto render or preview
            if watch:
                print("\nðŸ”„ Step 2: Starting Quarto in watch mode...")
                print("Press Ctrl+C to stop watching")
                subprocess.run(["quarto", "preview", "--no-browser"])
            else:
                print("\nðŸ”¨ Step 2: Building site with Quarto...")

                stop_event = threading.Event()
                progress_thread = threading.Thread(
                    target=show_progress, args=(stop_event, "   Rendering")
                )
                progress_thread.start()

                result = subprocess.run(["quarto", "render"], capture_output=True, text=True)

                stop_event.set()
                progress_thread.join()

                if result.returncode != 0:
                    print("\nâŒ quarto render failed:")
                    print(result.stderr)
                    sys.exit(1)
                else:
                    print("\nâœ… Site built successfully")
                    site_path = self.project_path / "_site" / "index.html"
                    if site_path.exists():
                        print(f"\nðŸŽ‰ Your site is ready! Open: {site_path}")
                    else:
                        print(f"\nðŸŽ‰ Your site is ready in: {self.project_path / '_site'}")

        finally:
            os.chdir(original_dir)

    def preview(self) -> None:
        """
        Build and serve the documentation site locally.

        Runs quartodoc build, then starts a local server with quarto preview.

        Examples
        --------
        Preview the documentation:

        ```python
        from great_docs import GreatDocs

        docs = GreatDocs()
        docs.preview()
        ```
        """
        import subprocess
        import sys

        print("Building and previewing documentation...")

        # Change to docs directory
        original_dir = os.getcwd()
        try:
            os.chdir(self.project_path)

            # Step 1: Run quartodoc build
            print("\nðŸ“š Step 1: Generating API reference with quartodoc...")
            result = subprocess.run(
                [sys.executable, "-m", "quartodoc", "build"], capture_output=True, text=True
            )

            if result.returncode != 0:
                print("âŒ quartodoc build failed:")
                # Check if quartodoc is not installed
                if "No module named quartodoc" in result.stderr:
                    print("\nâš ï¸  quartodoc is not installed in your environment.")
                    print("\nTo fix this, install quartodoc:")
                    print(f"  {sys.executable} -m pip install quartodoc")
                    print("\nOr if using pip directly:")
                    print("  pip install quartodoc")
                else:
                    print(result.stderr)
                return
            else:
                print("âœ… API reference generated")

            # Step 2: Run quarto preview
            print("\nðŸŒ Step 2: Starting preview server...")
            print("Press Ctrl+C to stop the server")
            subprocess.run(["quarto", "preview"])

        finally:
            os.chdir(original_dir)
